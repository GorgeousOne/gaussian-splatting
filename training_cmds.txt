---- TRAINING

# convert from images.txt to .bin
colmap model_converter --input_path sparse/0 --output_path sparse/0 --output_type BIN


# train dataset
python train.py -s /home/mighty/repos/datasets/tandt/train/ -m ./output/model-name --eval
python ./train.py -s /home/mighty/repos/datasets/hah_esszimmer2/ --eval --data_device=cpu -m ./output/hah_01-22_16_30

# train with depth regularizazion
python train.py -s /home/mighty/repos/datasets/tandt/train/ -d /home/mighty/repos/datasets/tandt/train/depths/ -m ./output/model-name --eval

# exposure compensation paramters
--exposure_lr_init 0.001 --exposure_lr_final 0.0001 --exposure_lr_delay_steps 5000 --exposure_lr_delay_mult 0.001 --train_test_exp

# voxel pruning parameters
--voxel /home/mighty/repos/datasets/db/playroom/metashape_reco/occupancy_grid.npz
--voxel_iterations 5000, ...

# resume from checkpoint (?)
python train.py -s /home/mighty/repos/datasets/tandt/train/ --start_checkpoint ./output/x/chkpnt.pth



---- EVALUATION


# render with trained model
python render.py -m ./output/x

# generate metrics
# you need to create a sparse/0/test.txt with image names to exclude from training (with extension)
python metrics.py --model_paths ./output/x

# run interactive viewer
./SIBR_viewers/install/bin/SIBR_gaussianViewer_app -m ./output/x/



---- DEPTH TRAINING

# generate depth estimations
# use in conda env "depth-anything"
# in directory repos
python ./Depth-Anything-V2/run.py --encoder vitl --pred-only --grayscale --img-path /home/mighty/repos/datasets/tandt/train/images/ --outdir /home/mighty/repos/datasets/tandt/train/depths/
python ./Depth-Anything-V2/run.py --encoder vitl --pred-only --grayscale --img-path /home/mighty/repos/datasets/db/playroom/images/ --outdir /home/mighty/repos/datasets/db/playroom/depths/

# indoor scenes
python run.py \
  --encoder vitl \
  --load-from checkpoints/depth_anything_v2_metric_hypersim_vitl.pth \
  --max-depth 20 \
  --img-path /home/mighty/repos/datasets/hah_esszimmer2/images/ \
  --outdir /home/mighty/repos/datasets/hah_esszimmer2/any_depth/ \
  --pred-only \
  --save-numpy \
  --grayscale

[--input-size <size>]



# generate depth scaling json
# "gaussian-splatting" again
python utils/make_depth_scale.py --base_dir /home/mighty/repos/datasets/tandt/train/ --depths_dir /home/mighty/repos/datasets/tandt/train/depths/
python utils/make_depth_scale.py --base_dir /home/mighty/repos/datasets/db/playroom/ --depths_dir /home/mighty/repos/datasets/db/playroom/depths/

---- EXPORTING CHANGES

git diff -w main...frequency-injection -- train.py depth_pruning/make_occupancy.py scene/gaussian_model.py > patch.diff
#-w ignores all whitespace changes